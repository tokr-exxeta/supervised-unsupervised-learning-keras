{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dbbc41c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab24e48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ebeeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37476c25",
   "metadata": {},
   "source": [
    "## Daten importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b57dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e03627d",
   "metadata": {},
   "source": [
    "Bilder sind keine 1D arrays of size 784 aber 28x28 array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6614936",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fcad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d556c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93db2ff8",
   "metadata": {},
   "source": [
    "## Aufteilung in Train/Test und Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51ad2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000]/ 255.0, X_train_full[5000:] / 255.0 #Aufteilung in train und validation set und Normalisierung (0-1) von typ float\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "X_test  = X_test/ 255.0\n",
    "\n",
    "#Durch 255 Teilen um Farbwerte zwischen 0-1 zu skalieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d05bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9872c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb5bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1601603",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ce8f9b",
   "metadata": {},
   "source": [
    "## Model with Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential() # einfachste Art von neuronalem Netz\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28])) # Konvertiert jedes Bild in ein 1D-Array\n",
    "model.add(keras.layers.Dense(300, activation='relu')) # Hidden Layer with 300 Neurons, benutzt Relu als activation function\n",
    "model.add(keras.layers.Dense(100, activation='relu')) # second dense hidden layer\n",
    "model.add(keras.layers.Dense(10, activation='softmax')) # 10 Output Neuronen --> 1 f체r jede Klasse, softmax activation da Klassen exklusiv sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19365d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e8a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d32d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"sgd\",metrics=[\"accuracy\"]) #learning rate by default = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24167d54",
   "metadata": {},
   "source": [
    "## Falls Trainingsset deutlich besser als Testset performt  --- Overfitting Gefahr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f169c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train, epochs=30, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ede2d",
   "metadata": {},
   "source": [
    "## Loss plotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f19094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1) #set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6e15f4",
   "metadata": {},
   "source": [
    "Hyperparameter-Tuning: 1. Learning rate ver채ndern. 2. Anderen Optimizer 3. Anzahl Layer 4. Anzahl Neuronen per Layer 5. Activation function der Hidden-Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd234b86",
   "metadata": {},
   "source": [
    "## Evaluierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7422d4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ada654a",
   "metadata": {},
   "source": [
    "## Predict-Methode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0120f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_test[2],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49de02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = model.predict(X_test[0:3]) #Klassifizieren der Wahrscheinlichkeit f체r die ersten 3 Bilder im Testset\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ae8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test[:3])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4490a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33543304",
   "metadata": {},
   "source": [
    "## fremdes Bild einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fefb814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "img = cv2.imread('../Bilder/Hose_test.jpg',3)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1fa781",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7fdb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.resize(img,(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650a80a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e159f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.bitwise_not(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e61ed2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img2,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f37c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pic = np.array(img2).reshape((1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120b3f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(test_pic)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24a8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a005e",
   "metadata": {},
   "source": [
    "## CNN - Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d004ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.Input(shape=[28,28,1]),\n",
    "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2), #each spatial dimension will be divided by factor 2\n",
    "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.Conv2D(128,3,activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(256,3,activation=\"relu\", padding=\"same\"), #common practice to double the number of filters after each pooling layer\n",
    "    keras.layers.Conv2D(256,3,activation=\"relu\", padding=\"same\"),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Flatten(), #dense layer expects 1D array but Conv-layers have 2D array\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5), #reducing overfitting\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcf3b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee66c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"sgd\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15d7c17",
   "metadata": {},
   "source": [
    "## Reshape der Daten f체r CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50ab555",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((-1,28,28,1))\n",
    "X_valid = X_valid.reshape((-1,28,28,1))\n",
    "X_test = X_test.reshape((-1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d516cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c1280",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45203f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train, epochs=30, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533fa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f, axarr = plt.subplots(3,4)\n",
    "FIRST_IMAGE=0\n",
    "SECOND_IMAGE=23\n",
    "THIRD_IMAGE=28\n",
    "CONVOLUTION_NUMBER = 6\n",
    "from tensorflow.keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "for x in range(0,4):  \n",
    "    f1 = activation_model.predict(X_valid[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[0,x].grid(False)\n",
    "    f2 = activation_model.predict(X_valid[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[1,x].grid(False)\n",
    "    f3 = activation_model.predict(X_valid[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[2,x].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4280473",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"fashion_mnist.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
